[Data]
glove_path = ./emb/glove.6B.100d.txt
bert_path = ./emb/bert-base-uncased

[Save]
save = True

[Network]
word_dims = 100
dropout_embed = 0.33
dropout_mlp = 0.15
word_num_layers = 2 
word_hidden_size = 128
graph_num_layers = 2
sent_num_layers = 2
sent_hidden_size = 256
dropout_input = 0.0
dropout_hidden = 0.33

[Optimizer]
learning_rate = 5e-4
bert_lr = 2e-5
decay = .75
decay_steps = 2000
beta_1 = .9
beta_2 = .98
epsilon = 1e-12
clip = 5.0

[Run]
threads = 2
epochs = 16
train_batch_size = 2
test_batch_size = 4
log_interval = 500
early_stops = 5
save_after = 1
update_every = 2
